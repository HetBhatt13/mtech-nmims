{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20220807-Lab-3-MTech-AI",
      "provenance": [],
      "authorship_tag": "ABX9TyNpt8kDHN9Zl3stO3eByzar",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalProgTech/mtech-nmims/blob/master/speech-recognition/Lab-Work/20220807-Lab-3-MTech-AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S-ir6MJjIjO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "!kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess\n",
        "!unzip *.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n",
        "import IPython.display as ipd"
      ],
      "metadata": {
        "id": "ao0fXcxEjTx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dirname, _, filenames in os.walk('/content/emotion_speech/'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "Emq3hF4TjTuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = []\n",
        "class_series = []"
      ],
      "metadata": {
        "id": "1WiN73d7jTsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dirname, _, filenames in os.walk('/content/emotion_speech/'):\n",
        "    for filename in filenames:\n",
        "        filepath = os.path.join(dirname, filename)\n",
        "        class_series.append(filepath.split('/')[-1].replace('.wav','').split('_'))\n",
        "        files.append(filepath)\n",
        "data = pd.DataFrame(class_series, columns=['actress', 'word', 'class'])\n",
        "data['filename'] = files\n",
        "data = data.sample(frac=1)\n",
        "data = data.reset_index(drop=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Mgz4buCUjTp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "g7JLA0g8jTnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    ss = '/content/emotion_speech/YAF_neutral/YAF_germ_neutral.wav'\n",
        "    ss.split('/')[-1].replace('.wav','').split('_')"
      ],
      "metadata": {
        "id": "25dV-CrUjfOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['class'].value_counts()"
      ],
      "metadata": {
        "id": "LwIwPbjQjTiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_audio_feature_plots(path, class_, word, actress):\n",
        "    x , sr = librosa.load(path)\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    plt.title('Waveplot of '+class_+' '+actress+' for word '+word)\n",
        "    librosa.display.waveplot(x, sr=sr)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    plt.title('MFCC Spectral of '+class_+' '+actress+' for word '+word)\n",
        "    mfccs = librosa.feature.mfcc(y=x, sr=sr) # n_mfcc\n",
        "    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "    print(mfccs.shape)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    plt.title('Mel Spectrogram of '+class_+' '+actress+' for word '+word)\n",
        "    mel_spec = librosa.feature.melspectrogram(y=x, sr=sr)\n",
        "    librosa.display.specshow(mel_spec, sr=sr, x_axis='time')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SnbtW1cwjkt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "9I3-ULwCjkrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['actress'].value_counts()"
      ],
      "metadata": {
        "id": "U1n_hRN0jnMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = data[(data['class'] == 'angry') & (data['word'] == 'calm') & (data['actress'] == 'OAF')]\n",
        "get_audio_feature_plots(sample['filename'].values[0], sample['class'].values[0], sample['word'].values[0], sample['actress'].values[0])\n",
        "ipd.Audio(sample.filename.values[0])"
      ],
      "metadata": {
        "id": "fHvU72B4jnKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = data[(data['class'] == 'angry') & (data['word'] == 'calm') & (data['actress'] == 'YAF')]\n",
        "get_audio_feature_plots(sample['filename'].values[0], sample['class'].values[0], sample['word'].values[0], sample['actress'].values[0])\n",
        "ipd.Audio(sample.filename.values[0])"
      ],
      "metadata": {
        "id": "5oKWgdWEjnHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = data[(data['class'] == 'fear') & (data['word'] == 'calm') & (data['actress'] == 'YAF')]\n",
        "get_audio_feature_plots(sample['filename'].values[0], sample['class'].values[0], sample['word'].values[0], sample['actress'].values[0])\n",
        "ipd.Audio(sample.filename.values[0])"
      ],
      "metadata": {
        "id": "p20CQesQjnEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = data[(data['class'] == 'fear') & (data['word'] == 'calm') & (data['actress'] == 'OAF')]\n",
        "get_audio_feature_plots(sample['filename'].values[0], sample['class'].values[0], sample['word'].values[0], sample['actress'].values[0])\n",
        "ipd.Audio(sample.filename.values[0])"
      ],
      "metadata": {
        "id": "YnVhxoOyjm-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "FrzUZBg8jwOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extractions"
      ],
      "metadata": {
        "id": "Pa5BwDCojyDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mfcc_features(path):\n",
        "    mfccs = []\n",
        "    try:\n",
        "        x , sr = librosa.load(path, res_type='kaiser_fast')\n",
        "        mfccs = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=128)\n",
        "        mfccs = np.mean(mfccs.T,axis=0)\n",
        "    except:\n",
        "        print('Error reading audio')\n",
        "    return mfccs"
      ],
      "metadata": {
        "id": "cAHT-jQAjm56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_melspec_features(path):\n",
        "    melspec = []\n",
        "    try:\n",
        "        x , sr = librosa.load(path, res_type='kaiser_fast')\n",
        "        melspec = librosa.feature.melspectrogram(y=x, sr=sr, n_mels=128)\n",
        "        melspec = np.mean(melspec.T,axis=0)\n",
        "    except:\n",
        "        print('Error reading audio')\n",
        "    return melspec"
      ],
      "metadata": {
        "id": "LZttSL8njkor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X_df = pd.DataFrame(data['filename'].apply(lambda x: create_mfcc_features(x)).tolist())\n",
        "X_df.head()"
      ],
      "metadata": {
        "id": "o7dWOZRajkmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.shape"
      ],
      "metadata": {
        "id": "TQ6-eQcij3-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(data['class'])\n",
        "y = encoder.transform(data['class'])"
      ],
      "metadata": {
        "id": "HC9zgN2cj36q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "xqbNYJwdj33o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(np.array(X_df), y, test_size=0.10)"
      ],
      "metadata": {
        "id": "N8LEAQfmj30s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_val.shape"
      ],
      "metadata": {
        "id": "BA0IIX6xj3wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 16, 8, 1)\n",
        "x_val = x_val.reshape(x_val.shape[0], 16, 8, 1)"
      ],
      "metadata": {
        "id": "PvsmYfN9kAtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model"
      ],
      "metadata": {
        "id": "BPBdzVoAkO0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(16, 8, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding = \"same\"),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding = \"same\"),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(data['class'].unique()), activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rpcrZom4kApX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jEzJrQv9kAlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=20)"
      ],
      "metadata": {
        "id": "8l8VFLmNkAh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_val, y_val)"
      ],
      "metadata": {
        "id": "TILFaHkhjkjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_val = model.predict(x_val)\n",
        "pred_val = np.argmax(prob_val, axis=1)\n",
        "pred_val = encoder.inverse_transform(pred_val)"
      ],
      "metadata": {
        "id": "6cuVioEtkKPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(encoder.inverse_transform(y_val), pred_val)"
      ],
      "metadata": {
        "id": "Fwt7_3NckKKA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}